{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "75QTd5R4s5GP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "i2PvsF_Gstmq",
        "outputId": "a83bcff8-3453-4f2a-ebe0-e6602e30f21c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-25 22:51:00--  https://cernbox.cern.ch/remote.php/dav/public-files/AtBT8y4MiQYFcgc/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5\n",
            "Resolving cernbox.cern.ch (cernbox.cern.ch)... 128.142.170.17, 128.142.53.28, 128.142.53.35, ...\n",
            "Connecting to cernbox.cern.ch (cernbox.cern.ch)|128.142.170.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 119703858 (114M) [application/octet-stream]\n",
            "Saving to: ‘SinglePhoton.hdf5’\n",
            "\n",
            "SinglePhoton.hdf5   100%[===================>] 114.16M   248KB/s    in 3m 36s  \n",
            "\n",
            "2025-03-25 22:54:37 (542 KB/s) - ‘SinglePhoton.hdf5’ saved [119703858/119703858]\n",
            "\n",
            "--2025-03-25 22:54:37--  https://cernbox.cern.ch/remote.php/dav/public-files/FbXw3V4XNyYB3oA/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5\n",
            "Resolving cernbox.cern.ch (cernbox.cern.ch)... 128.142.170.17, 128.142.53.35, 128.142.53.28, ...\n",
            "Connecting to cernbox.cern.ch (cernbox.cern.ch)|128.142.170.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 128927319 (123M) [application/octet-stream]\n",
            "Saving to: ‘SingleElectron.hdf5’\n",
            "\n",
            "SingleElectron.hdf5 100%[===================>] 122.95M   293KB/s    in 4m 20s  \n",
            "\n",
            "2025-03-25 22:58:58 (484 KB/s) - ‘SingleElectron.hdf5’ saved [128927319/128927319]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \"https://cernbox.cern.ch/remote.php/dav/public-files/AtBT8y4MiQYFcgc/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5\" -O SinglePhoton.hdf5\n",
        "!wget --no-check-certificate \"https://cernbox.cern.ch/remote.php/dav/public-files/FbXw3V4XNyYB3oA/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5\" -O SingleElectron.hdf5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(path):\n",
        "    with h5py.File(path, \"r\") as f:\n",
        "        X = f['X'][:]\n",
        "        y = f['y'][:]\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "NPatVuvVys45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_p, y_p = load_dataset(\"SinglePhoton.hdf5\")\n",
        "X_e, y_e = load_dataset(\"SingleElectron.hdf5\")"
      ],
      "metadata": {
        "id": "1_cSHllyy12Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.concatenate([X_p[:150000], X_e[:150000]], axis=0)\n",
        "y = np.concatenate([y_p[:150000], y_e[:150000]], axis=0)"
      ],
      "metadata": {
        "id": "rlu3x2qVzJ5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.mean(X, axis=(0, 1, 2))\n",
        "std = np.std(X, axis=(0, 1, 2))\n",
        "X = (X - mean) / std"
      ],
      "metadata": {
        "id": "rUxxGEP-6ZW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EGTSCD52MKX",
        "outputId": "4383d748-14fc-48ec-d91f-3c0160f4092e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300000, 32, 32, 2) (300000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_tensor = torch.tensor(X, dtype=torch.float32).permute(0, 3, 1, 2)  # (N, C, H, W)\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
      ],
      "metadata": {
        "id": "clzyIOWV1XBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64)"
      ],
      "metadata": {
        "id": "gXwziRL03rCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, 1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, 1, stride),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        return F.relu(out)\n",
        "\n",
        "class ResNet15(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = BasicBlock(2, 16)\n",
        "        self.layer2 = BasicBlock(16, 32, stride=2)\n",
        "        self.layer3 = BasicBlock(32, 64, stride=2)\n",
        "        self.layer4 = BasicBlock(64, 128, stride=2)\n",
        "        self.layer5 = BasicBlock(128, 128)\n",
        "        self.layer6 = BasicBlock(128, 128)\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(128, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "        x = self.layer6(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(x)\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "mVxt2jir5Ezg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "IeoV-CDf5IMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4Q-Oxlb5Jhz",
        "outputId": "1e8aaa02-2af0-4479-b7c0-8405df14f9b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet15().to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.002, weight_decay=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 训练过程\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        pred = outputs.argmax(dim=1)\n",
        "        correct += (pred == y_batch).sum().item()\n",
        "\n",
        "    acc = correct / len(train_dataset)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}, Train Acc: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYoLg0AS5PIZ",
        "outputId": "0ccd56f0-ba9d-4dfd-d4b0-058bac2e4449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2317.6611, Train Acc: 0.6666\n",
            "Epoch 2, Loss: 2167.5605, Train Acc: 0.7079\n",
            "Epoch 3, Loss: 2125.6344, Train Acc: 0.7157\n",
            "Epoch 4, Loss: 2105.2474, Train Acc: 0.7201\n",
            "Epoch 5, Loss: 2096.4016, Train Acc: 0.7217\n",
            "Epoch 6, Loss: 2088.6314, Train Acc: 0.7233\n",
            "Epoch 7, Loss: 2085.0965, Train Acc: 0.7247\n",
            "Epoch 8, Loss: 2080.0359, Train Acc: 0.7248\n",
            "Epoch 9, Loss: 2079.0086, Train Acc: 0.7248\n",
            "Epoch 10, Loss: 2072.0367, Train Acc: 0.7265\n",
            "Epoch 11, Loss: 2071.2178, Train Acc: 0.7263\n",
            "Epoch 12, Loss: 2072.1049, Train Acc: 0.7257\n",
            "Epoch 13, Loss: 2067.3969, Train Acc: 0.7276\n",
            "Epoch 14, Loss: 2067.1409, Train Acc: 0.7269\n",
            "Epoch 15, Loss: 2064.2255, Train Acc: 0.7271\n",
            "Epoch 16, Loss: 2063.3967, Train Acc: 0.7278\n",
            "Epoch 17, Loss: 2062.7218, Train Acc: 0.7275\n",
            "Epoch 18, Loss: 2061.6298, Train Acc: 0.7285\n",
            "Epoch 19, Loss: 2062.4959, Train Acc: 0.7278\n",
            "Epoch 20, Loss: 2059.2545, Train Acc: 0.7282\n",
            "Epoch 21, Loss: 2057.2446, Train Acc: 0.7298\n",
            "Epoch 22, Loss: 2055.9964, Train Acc: 0.7291\n",
            "Epoch 23, Loss: 2057.8133, Train Acc: 0.7292\n",
            "Epoch 24, Loss: 2057.9799, Train Acc: 0.7289\n",
            "Epoch 25, Loss: 2057.4263, Train Acc: 0.7289\n",
            "Epoch 26, Loss: 2056.4852, Train Acc: 0.7283\n",
            "Epoch 27, Loss: 2055.6858, Train Acc: 0.7294\n",
            "Epoch 28, Loss: 2056.4400, Train Acc: 0.7287\n",
            "Epoch 29, Loss: 2053.8962, Train Acc: 0.7296\n",
            "Epoch 30, Loss: 2052.8713, Train Acc: 0.7293\n",
            "Epoch 31, Loss: 2051.7094, Train Acc: 0.7304\n",
            "Epoch 32, Loss: 2051.3201, Train Acc: 0.7301\n",
            "Epoch 33, Loss: 2053.4879, Train Acc: 0.7300\n",
            "Epoch 34, Loss: 2051.7002, Train Acc: 0.7298\n",
            "Epoch 35, Loss: 2051.5076, Train Acc: 0.7308\n",
            "Epoch 36, Loss: 2049.9722, Train Acc: 0.7310\n",
            "Epoch 37, Loss: 2051.9562, Train Acc: 0.7300\n",
            "Epoch 38, Loss: 2050.0716, Train Acc: 0.7300\n",
            "Epoch 39, Loss: 2051.0132, Train Acc: 0.7304\n",
            "Epoch 40, Loss: 2050.9802, Train Acc: 0.7302\n",
            "Epoch 41, Loss: 2051.3292, Train Acc: 0.7306\n",
            "Epoch 42, Loss: 2049.0295, Train Acc: 0.7304\n",
            "Epoch 43, Loss: 2048.6507, Train Acc: 0.7308\n",
            "Epoch 44, Loss: 2049.9735, Train Acc: 0.7302\n",
            "Epoch 45, Loss: 2052.9405, Train Acc: 0.7302\n",
            "Epoch 46, Loss: 2048.7328, Train Acc: 0.7308\n",
            "Epoch 47, Loss: 2049.0009, Train Acc: 0.7293\n",
            "Epoch 48, Loss: 2049.0730, Train Acc: 0.7308\n",
            "Epoch 49, Loss: 2047.8723, Train Acc: 0.7304\n",
            "Epoch 50, Loss: 2048.9912, Train Acc: 0.7309\n",
            "Epoch 51, Loss: 2048.8296, Train Acc: 0.7307\n",
            "Epoch 52, Loss: 2050.2807, Train Acc: 0.7301\n",
            "Epoch 53, Loss: 2046.6324, Train Acc: 0.7301\n",
            "Epoch 54, Loss: 2049.4981, Train Acc: 0.7302\n",
            "Epoch 55, Loss: 2050.1364, Train Acc: 0.7307\n",
            "Epoch 56, Loss: 2047.2227, Train Acc: 0.7310\n",
            "Epoch 57, Loss: 2047.3692, Train Acc: 0.7306\n",
            "Epoch 58, Loss: 2048.0302, Train Acc: 0.7310\n",
            "Epoch 59, Loss: 2047.3021, Train Acc: 0.7307\n",
            "Epoch 60, Loss: 2047.9514, Train Acc: 0.7306\n",
            "Epoch 61, Loss: 2047.1922, Train Acc: 0.7309\n",
            "Epoch 62, Loss: 2045.0971, Train Acc: 0.7312\n",
            "Epoch 63, Loss: 2047.3982, Train Acc: 0.7309\n",
            "Epoch 64, Loss: 2048.8477, Train Acc: 0.7306\n",
            "Epoch 65, Loss: 2049.0884, Train Acc: 0.7314\n",
            "Epoch 66, Loss: 2047.6722, Train Acc: 0.7301\n",
            "Epoch 67, Loss: 2048.6692, Train Acc: 0.7304\n",
            "Epoch 68, Loss: 2045.1367, Train Acc: 0.7311\n",
            "Epoch 69, Loss: 2045.2457, Train Acc: 0.7313\n",
            "Epoch 70, Loss: 2045.5745, Train Acc: 0.7312\n",
            "Epoch 71, Loss: 2045.6029, Train Acc: 0.7313\n",
            "Epoch 72, Loss: 2047.2719, Train Acc: 0.7314\n",
            "Epoch 73, Loss: 2045.8736, Train Acc: 0.7320\n",
            "Epoch 74, Loss: 2050.2165, Train Acc: 0.7308\n",
            "Epoch 75, Loss: 2049.2465, Train Acc: 0.7306\n",
            "Epoch 76, Loss: 2044.4619, Train Acc: 0.7312\n",
            "Epoch 77, Loss: 2043.8266, Train Acc: 0.7316\n",
            "Epoch 78, Loss: 2046.1338, Train Acc: 0.7312\n",
            "Epoch 79, Loss: 2044.0491, Train Acc: 0.7308\n",
            "Epoch 80, Loss: 2045.9406, Train Acc: 0.7313\n",
            "Epoch 81, Loss: 2045.2247, Train Acc: 0.7313\n",
            "Epoch 82, Loss: 2045.0367, Train Acc: 0.7317\n",
            "Epoch 83, Loss: 2046.8210, Train Acc: 0.7308\n",
            "Epoch 84, Loss: 2045.8484, Train Acc: 0.7319\n",
            "Epoch 85, Loss: 2045.8704, Train Acc: 0.7311\n",
            "Epoch 86, Loss: 2044.5332, Train Acc: 0.7315\n",
            "Epoch 87, Loss: 2046.0285, Train Acc: 0.7315\n",
            "Epoch 88, Loss: 2045.4932, Train Acc: 0.7307\n",
            "Epoch 89, Loss: 2048.4170, Train Acc: 0.7305\n",
            "Epoch 90, Loss: 2044.8641, Train Acc: 0.7319\n",
            "Epoch 91, Loss: 2044.8397, Train Acc: 0.7321\n",
            "Epoch 92, Loss: 2045.9035, Train Acc: 0.7316\n",
            "Epoch 93, Loss: 2045.4703, Train Acc: 0.7318\n",
            "Epoch 94, Loss: 2045.6702, Train Acc: 0.7311\n",
            "Epoch 95, Loss: 2045.2959, Train Acc: 0.7308\n",
            "Epoch 96, Loss: 2044.7267, Train Acc: 0.7315\n",
            "Epoch 97, Loss: 2047.7539, Train Acc: 0.7316\n",
            "Epoch 98, Loss: 2043.7364, Train Acc: 0.7318\n",
            "Epoch 99, Loss: 2046.4649, Train Acc: 0.7311\n",
            "Epoch 100, Loss: 2044.9058, Train Acc: 0.7322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        outputs = model(X_batch)\n",
        "        pred = outputs.argmax(dim=1)\n",
        "        correct += (pred == y_batch).sum().item()\n",
        "\n",
        "test_acc = correct / len(test_dataset)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRkkanOD5S45",
        "outputId": "49e364fa-901d-415b-f65f-0ed2c1c1f0af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7272\n"
          ]
        }
      ]
    }
  ]
}